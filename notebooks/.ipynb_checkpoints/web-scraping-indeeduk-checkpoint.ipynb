{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for scraping from indeed.co.uk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "\n",
    "import requests, bs4, time\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define functions for parsing HTML\n",
    "\n",
    "def extract_job_title_from_result(soup): \n",
    "    jobs = []\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "        for a in div.find_all(name=\"a\", attrs={\"data-tn-element\":\"jobTitle\"}):\n",
    "            jobs.append(a[\"title\"])\n",
    "    return(jobs)\n",
    "\n",
    "def extract_salary_from_result(soup): \n",
    "    salaries = []\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "        try:\n",
    "            salaries.append(div.find(name=\"span\",attrs={\"class\":\"salaryText\"}).text)\n",
    "        except:\n",
    "            salaries.append(\"Nothing_found\")\n",
    "    return(salaries)\n",
    "\n",
    "def extract_location_from_result(soup): \n",
    "    locations = []\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "        try:\n",
    "            locations.append(div.find(\"span\", attrs={\"class\": \"location accessible-contrast-color-location\"}).text)\n",
    "        except:\n",
    "            locations.append(\"Nothing_found\")\n",
    "   \n",
    "    return(locations)\n",
    "\n",
    "def extract_description_from_result(soup): \n",
    "    description = []\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "        try:\n",
    "            description.append(div.find(\"div\", attrs={\"class\": \"summary\"}).text)\n",
    "        except:\n",
    "            description.append(\"Nothing_found\")\n",
    "   \n",
    "    return(description)\n",
    "\n",
    "def extract_date_from_result(soup): \n",
    "    date = []\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "        try:\n",
    "            date.append(div.find(\"span\", attrs={\"class\": \"date\"}).text)\n",
    "        except:\n",
    "            date.append(\"Nothing_found\")\n",
    "   \n",
    "    return(date)\n",
    "\n",
    "def extract_company_from_result(soup): \n",
    "    company = []\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "        try:\n",
    "            company.append(div.find(\"span\", attrs={\"class\": \"company\"}).text)\n",
    "        except:\n",
    "            company.append(\"Nothing_found\")\n",
    "   \n",
    "    return(company)\n",
    "\n",
    "def extract_links(soup):\n",
    "    links =[]\n",
    "    for div in soup.find_all(name='a', attrs={'class':'jobtitle turnstileLink'}):\n",
    "        links.append('https://www.indeed.co.uk'+str(div['href']))\n",
    "    return links\n",
    "\n",
    "def extract_full_desc(soup):\n",
    "    text=[x.text for x in soup.find_all(name=\"div\",attrs={\"id\":\"jobDescriptionText\"})]\n",
    "    return text\n",
    "\n",
    "\n",
    "def extract_headlines_from_result(soup): \n",
    "    headlines = pd.DataFrame(columns=\"location\",\"type\",\"salary\")\n",
    "    list=[x.text for x in soup.find_all(name=\"span\",attrs={\"class\":\"jobsearch-JobMetadataHeader-iconLabel\"})]\n",
    "    try:\n",
    "        headlines['location']\n",
    "    \n",
    "        except:\n",
    "            salaries.append(\"Nothing_found\")\n",
    "    return(salaries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping code:\n",
    "\n",
    "#decide what search term to use for finding jobs\n",
    "searchTerm=\"data\"\n",
    "\n",
    "#create empty data frame with column headers\n",
    "ads=pd.DataFrame(columns=['company','job_title','salary','location','description','date','full_description','other_deets'])\n",
    "\n",
    "# loop for scraping\n",
    "\n",
    "for i in range(0,1000,10):\n",
    "    time.sleep(1) #ensuring at least 1 second between page grabs\n",
    "    url = \"https://www.indeed.co.uk/jobs?q=\"+searchTerm+\"&filter=0&l=\"+\"&start=\"+str(i)\n",
    "    res = requests.get(url)\n",
    "    soup = bs4.BeautifulSoup(res.content)\n",
    "    df=pd.DataFrame()\n",
    "    df['company']=extract_company_from_result(soup)\n",
    "    df['job_title']=extract_job_title_from_result(soup)\n",
    "    df['salary']=extract_salary_from_result(soup)\n",
    "    df['location']=extract_location_from_result(soup)\n",
    "    df['description']=extract_description_from_result(soup)\n",
    "    df['date']=extract_date_from_result(soup)\n",
    "    \n",
    "    sub_urls=extract_links(soup)\n",
    "    text_list=[]\n",
    "    deets_list=[]\n",
    "    for j in sub_urls:\n",
    "        res_sub = requests.get(j)\n",
    "        soup_sub = bs4.BeautifulSoup(res_sub.content)\n",
    "        desc=extract_full_desc(soup_sub)\n",
    "        text_list.append(desc)\n",
    "        other_deets=extract_headlines_from_result(soup_sub)\n",
    "        deets_list.append(other_deets)\n",
    "    df['full_description']=text_list\n",
    "    df['other_deets']=other_deets\n",
    "    ads=ads.append(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(704, 8)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#establish how many ads had no salary\n",
    "ads[ads['salary']==\"Nothing_found\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print data to csv\n",
    "#ads.to_csv(r\"data\\indeed_scrape_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
