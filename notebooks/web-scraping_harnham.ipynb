{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for scraping Harham.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, bs4, time\n",
    "import pandas as pd\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from datetime import date\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_links(soup):\n",
    "    links =[]\n",
    "    for div in soup.find_all(name='a', attrs={'class':'job-block__title-link'}):\n",
    "        links.append(div['href'])\n",
    "    return links\n",
    "\n",
    "def extract_salary(page_soup):\n",
    "    for div in page_soup.find_all(\"div\",{\"class\",\"cop-widget dynamic-widget salary-widget\"}):\n",
    "         a=[x.text for x in div.find_all(\"span\")]\n",
    "    return a[0].lstrip('Salary:\\n').rstrip(' \\n')\n",
    "\n",
    "\n",
    "def extract_location(page_soup):\n",
    "    a=[]\n",
    "    for div in page_soup.find_all(\"div\",{\"class\",\"cop-widget dynamic-widget text-widget\"}):\n",
    "         a.append([x.text for x in div.find_all(\"div\",{\"class\",\"\"})])\n",
    "    return a[0]\n",
    "\n",
    "def extract_jobref(page_soup):\n",
    "    a=[]\n",
    "    for div in page_soup.find_all(\"div\",{\"class\",\"cop-widget dynamic-widget text-widget\"}):\n",
    "         a.append([x.text for x in div.find_all(\"div\",{\"class\",\"\"})])\n",
    "    return a[1]\n",
    "\n",
    "def extract_type(page_soup):\n",
    "    a=[x.text for x in page_soup.find_all(\"li\",{\"class\",\"JobType-wrapper\"})]\n",
    "    type=a[0].lstrip('Job type\\n                    \\n').rstrip(' \\n')\n",
    "    return type\n",
    "\n",
    "def extract_description(page_soup):\n",
    "    b=page_soup.find_all(\"div\",{\"class\":\"cop-widget dynamic-widget description-widget\"})\n",
    "    for div  in b:\n",
    "        c=str([x.text for x in div.find_all(\"p\")]) +\" \"+ str([x.text for x in div.find_all(\"li\")])\n",
    "        desc=''.join(c)\n",
    "    return desc\n",
    "\n",
    "def extract_job_title(page_soup):\n",
    "    return [x.text for x in page_soup.find_all(\"strong\")][0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1166"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#urls for UK data science jobs\n",
    "links=[]\n",
    "for i in range(1,4):\n",
    "    url=\"https://www.harnham.com/jobs?options=1111,652&page=\"+str(i)+\"&size=60\"\n",
    "    req=Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    webpage=urlopen(req).read()\n",
    "    page_soup = soup(webpage, \"html.parser\")\n",
    "    a=extract_links(page_soup)\n",
    "    for element in a:\n",
    "        links.append(element)\n",
    "\n",
    "#urls for UK marketing/insight jobs\n",
    "for i in range(1,8):\n",
    "    url=\"https://www.harnham.com/jobs?options=973,652&page=\"+str(i)+\"&size=60\"\n",
    "    req=Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    webpage=urlopen(req).read()\n",
    "    page_soup = soup(webpage, \"html.parser\")\n",
    "    a=extract_links(page_soup)\n",
    "    for element in a:\n",
    "        links.append(element)\n",
    "            \n",
    "#urls digital analytics\n",
    "for i in range(1,5):\n",
    "    url=\"https://www.harnham.com/jobs?options=1035,652&page=\"+str(i)+\"&size=60\"\n",
    "    req=Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    webpage=urlopen(req).read()\n",
    "    page_soup = soup(webpage, \"html.parser\")\n",
    "    a=extract_links(page_soup)\n",
    "    for element in a:\n",
    "        links.append(element)\n",
    "\n",
    "#urls for data and technology jobs\n",
    "for i in range(1,7):\n",
    "    url=\"https://www.harnham.com/jobs?options=972,652&page=\"+str(i)+\"&size=60\"\n",
    "    req=Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    webpage=urlopen(req).read()\n",
    "    page_soup = soup(webpage, \"html.parser\")\n",
    "    a=extract_links(page_soup)\n",
    "    for element in a:\n",
    "        links.append(element)\n",
    "    \n",
    "\n",
    "\n",
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "info=pd.DataFrame(columns=(\"job_ref\",\"job_title\",\"location\",\"salary\",\"description\",\"type\"))\n",
    "for urls in links:\n",
    "    time.sleep(1) #ensuring at least 1 second between page grabs\n",
    "    url=\"https://www.harnham.com\"+urls\n",
    "    req=Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    webpage=urlopen(req).read()\n",
    "    page_soup = soup(webpage, \"html.parser\")\n",
    "    df=pd.DataFrame()\n",
    "    df['job_ref']=[extract_jobref(page_soup)]\n",
    "    df['job_title']=[extract_job_title(page_soup)]\n",
    "    df['location']=[extract_location(page_soup)]\n",
    "    df['salary']=[extract_salary(page_soup)]\n",
    "    df['description']=[extract_description(page_soup)]\n",
    "    df['type']=[extract_type(page_soup)]\n",
    "    info=info.append(df,ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "info[\"extraction_date\"]= date.today()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_ref</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>description</th>\n",
       "      <th>type</th>\n",
       "      <th>extraction_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[7245/KD]</td>\n",
       "      <td>Pricing Data Scientist</td>\n",
       "      <td>[London]</td>\n",
       "      <td>£40000 - £50000 per annum + benefits + bonus</td>\n",
       "      <td>['Pricing Data Scientist ', 'London ', '£40,00...</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>2019-10-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[VACNM23wks1-]</td>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>[London]</td>\n",
       "      <td>£100000 - £110000 per annum + Benefits</td>\n",
       "      <td>['Lead Data ScientistRetailLondon£95,000 + ben...</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>2019-10-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[VASNF348rjhf0-23484]</td>\n",
       "      <td>Lead Machine Learning Engineer</td>\n",
       "      <td>[London]</td>\n",
       "      <td>£85000 - £100000 per annum + Benefits</td>\n",
       "      <td>['Lead Machine Learning EngineerDeep Learning ...</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>2019-10-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[VACNW\"M1-we]</td>\n",
       "      <td>NLP Scientist</td>\n",
       "      <td>[London]</td>\n",
       "      <td>£90000 - £100000 per annum + Benefits</td>\n",
       "      <td>['NLP ScientistLondon£90,000 - £100,000', 'OVE...</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>2019-10-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[67222/KD]</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>[London]</td>\n",
       "      <td>£70000 - £80000 per annum + benefits + bonus</td>\n",
       "      <td>['Senior Data Scientist ', 'London', '£70,000-...</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>2019-10-24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 job_ref                       job_title  location  \\\n",
       "0              [7245/KD]         Pricing Data Scientist   [London]   \n",
       "1         [VACNM23wks1-]             Lead Data Scientist  [London]   \n",
       "2  [VASNF348rjhf0-23484]  Lead Machine Learning Engineer  [London]   \n",
       "3          [VACNW\"M1-we]                   NLP Scientist  [London]   \n",
       "4             [67222/KD]          Senior Data Scientist   [London]   \n",
       "\n",
       "                                         salary  \\\n",
       "0  £40000 - £50000 per annum + benefits + bonus   \n",
       "1        £100000 - £110000 per annum + Benefits   \n",
       "2         £85000 - £100000 per annum + Benefits   \n",
       "3         £90000 - £100000 per annum + Benefits   \n",
       "4  £70000 - £80000 per annum + benefits + bonus   \n",
       "\n",
       "                                         description       type  \\\n",
       "0  ['Pricing Data Scientist ', 'London ', '£40,00...  Permanent   \n",
       "1  ['Lead Data ScientistRetailLondon£95,000 + ben...  Permanent   \n",
       "2  ['Lead Machine Learning EngineerDeep Learning ...  Permanent   \n",
       "3  ['NLP ScientistLondon£90,000 - £100,000', 'OVE...  Permanent   \n",
       "4  ['Senior Data Scientist ', 'London', '£70,000-...  Permanent   \n",
       "\n",
       "  extraction_date  \n",
       "0      2019-10-24  \n",
       "1      2019-10-24  \n",
       "2      2019-10-24  \n",
       "3      2019-10-24  \n",
       "4      2019-10-24  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print data to csv\n",
    "date=date.today()\n",
    "#info.to_csv(r\"harnham_scrape_data_{}.csv\".format(date))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to clean the data...\n",
    "First define cleaning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_location(df):\n",
    "    import re\n",
    "    for i in range(len(df['location'])):\n",
    "        rep = {\"[\": \"\",\n",
    "               \"]\": \"\",\n",
    "               \"''\": \"\",\n",
    "               \"'\": \"\"}\n",
    "        df['location'][i]=str(df['location'][i])\n",
    "        rep = dict((re.escape(k), v) for k, v in rep.items()) \n",
    "        pattern = re.compile(\"|\".join(rep.keys()))\n",
    "        df['location'][i]=(pattern.sub(lambda m: rep[re.escape(m.group(0))], df['location'][i]))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_duped_info_from_description(df):\n",
    "        df['description']=[x.replace(y,\"\") for x,y in zip(df['description'],df['location'])]\n",
    "        df['description']=[x.replace(y,\"\") for x,y in zip(df['description'],df['job_title'])]\n",
    "        df['description']=[x.replace(y,\"\") for x,y in zip(df['description'],df['salary'])]\n",
    "\n",
    "def clean_description(df):\n",
    "    import re\n",
    "    series=[]\n",
    "    for i in range(len(df['description'])):\n",
    "        rep = {\"[\": \"\",\n",
    "               \"]\": \"\",\n",
    "               \"|\": \"\",\n",
    "               \"''\": \"\",\n",
    "               \"'\": \"\",\n",
    "               \",\": \"\",\n",
    "               \"+\": \"\",\n",
    "               \"/\": \"\",\n",
    "               \"benefits\":\"\",\n",
    "               \"THE COMPANY\": \"\",\n",
    "               \"THE ROLE\": \"\",\n",
    "               \"THE BENEFITS\": \"\",\n",
    "               \"HOW TO APPLY\": \"\",\n",
    "               \"KEYWORDS\": \"\",\n",
    "               \"YOUR SKILLS AND EXPERIENCE\": \"\",\n",
    "               \"YOUR SKILLS AND EXPERTISE\": \"\",\n",
    "               \"Please register your interest by sending your CV via the Apply link on this page\":\"\",\n",
    "               \"BENEFITS\":\"\",\n",
    "               \"CONTACT\":\"\",\n",
    "               \"OVERVIEW\":\"\",\n",
    "               \"SALARY\":\"\",\n",
    "               \"For further details\":\"\",\n",
    "               \"to enquire about other roles please contact\":\"\",\n",
    "               \"Nick Mandella\":\"\",\n",
    "               \"Harnham\":\"\",\n",
    "               \"On a daily basis\":\"\",\n",
    "               \"you will be:\":\"\",\n",
    "               \"you will join:\":\"\",\n",
    "               \"!\":\"\",\n",
    "               \".\": \"\"}\n",
    "        rep = dict((re.escape(k), v) for k, v in rep.items()) \n",
    "        pattern = re.compile(\"|\".join(rep.keys()))\n",
    "        df['description'][i]=(pattern.sub(lambda m: rep[re.escape(m.group(0))],df['description'][i]))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_split_salary_range(df):\n",
    "    \n",
    "    df['salary_low']=df['salary'].str.split(\" - \", n = 1, expand = True)[0]\n",
    "    df['salary_high']=df['salary'].str.split(\" - \", n = 1, expand = True)[1]\n",
    "\n",
    "    for x in range(len(df[\"salary_high\"])):\n",
    "        if pd.isnull(df.loc[x,\"salary_high\"]):\n",
    "            df.loc[x,\"salary_high\"]=df.loc[x,\"salary_low\"]\n",
    "\n",
    "def clean_salary(df):\n",
    "    df['salary_low']=[x.split(\"£\",1)[1] for x in df['salary_low']]\n",
    "    df['salary_low']=[x.split(\"per\",1)[0] for x in df['salary_low']]\n",
    "    df['salary_high']=[x.split('£', 1)[1]for x in df['salary_high']]\n",
    "    df['salary_high']=[x.split('per', 1)[0]for x in df['salary_high']]\n",
    "    df['salary_high']=pd.to_numeric(df['salary_high'])\n",
    "    df['salary_low']=pd.to_numeric(df['salary_low'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run cleaning functions\n",
    "clean_location(info)\n",
    "remove_duped_info_from_description(info)\n",
    "clean_description(info)\n",
    "create_split_salary_range(info)\n",
    "clean_salary(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_ref</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>description</th>\n",
       "      <th>type</th>\n",
       "      <th>extraction_date</th>\n",
       "      <th>salary_low</th>\n",
       "      <th>salary_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[7245/KD]</td>\n",
       "      <td>Pricing Data Scientist</td>\n",
       "      <td>London</td>\n",
       "      <td>£40000 - £50000 per annum + benefits + bonus</td>\n",
       "      <td>£40000-£50000  Applying exploratory advance...</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>2019-10-24</td>\n",
       "      <td>40000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[VACNM23wks1-]</td>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>London</td>\n",
       "      <td>£100000 - £110000 per annum + Benefits</td>\n",
       "      <td>Retail£95000     are working with one of the l...</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>2019-10-24</td>\n",
       "      <td>100000</td>\n",
       "      <td>110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[VASNF348rjhf0-23484]</td>\n",
       "      <td>Lead Machine Learning Engineer</td>\n",
       "      <td>London</td>\n",
       "      <td>£85000 - £100000 per annum + Benefits</td>\n",
       "      <td>Deep Learning  NLP£85000 - £100000   are curre...</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>2019-10-24</td>\n",
       "      <td>85000</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[VACNW\"M1-we]</td>\n",
       "      <td>NLP Scientist</td>\n",
       "      <td>London</td>\n",
       "      <td>£90000 - £100000 per annum + Benefits</td>\n",
       "      <td>£90000 - £100000   are currently working exclu...</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>2019-10-24</td>\n",
       "      <td>90000</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[67222/KD]</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>London</td>\n",
       "      <td>£70000 - £80000 per annum + benefits + bonus</td>\n",
       "      <td>£70000-£80000    bonus Do you want to be a b...</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>2019-10-24</td>\n",
       "      <td>70000</td>\n",
       "      <td>80000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 job_ref                       job_title location  \\\n",
       "0              [7245/KD]         Pricing Data Scientist    London   \n",
       "1         [VACNM23wks1-]             Lead Data Scientist   London   \n",
       "2  [VASNF348rjhf0-23484]  Lead Machine Learning Engineer   London   \n",
       "3          [VACNW\"M1-we]                   NLP Scientist   London   \n",
       "4             [67222/KD]          Senior Data Scientist    London   \n",
       "\n",
       "                                         salary  \\\n",
       "0  £40000 - £50000 per annum + benefits + bonus   \n",
       "1        £100000 - £110000 per annum + Benefits   \n",
       "2         £85000 - £100000 per annum + Benefits   \n",
       "3         £90000 - £100000 per annum + Benefits   \n",
       "4  £70000 - £80000 per annum + benefits + bonus   \n",
       "\n",
       "                                         description       type  \\\n",
       "0     £40000-£50000  Applying exploratory advance...  Permanent   \n",
       "1  Retail£95000     are working with one of the l...  Permanent   \n",
       "2  Deep Learning  NLP£85000 - £100000   are curre...  Permanent   \n",
       "3  £90000 - £100000   are currently working exclu...  Permanent   \n",
       "4    £70000-£80000    bonus Do you want to be a b...  Permanent   \n",
       "\n",
       "  extraction_date  salary_low  salary_high  \n",
       "0      2019-10-24       40000        50000  \n",
       "1      2019-10-24      100000       110000  \n",
       "2      2019-10-24       85000       100000  \n",
       "3      2019-10-24       90000       100000  \n",
       "4      2019-10-24       70000        80000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-267cb666d2e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# check for salary anomalies\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'salary_high'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'salary_low'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#correct the mistake\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'salary_high'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'salary_high'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'salary_high'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m65000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# check for salary anomalies\n",
    "info[info['salary_high']/info['salary_low']>3]\n",
    "#correct the mistake\n",
    "info.loc[info['salary_high']==max(info['salary_high']),'salary_high']=65000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([11.,  0.,  0.,  7., 36., 40., 35., 20.,  9., 13.]),\n",
       " array([   550.,  13495.,  26440.,  39385.,  52330.,  65275.,  78220.,\n",
       "         91165., 104110., 117055., 130000.]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data['salary_high'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "word =[x.count(\"data engineer\") for x in data['description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for testing formulae\n",
    "#url=\"https://www.harnham.com/job/data-scientist-in-london-jid-2435\"\n",
    "#req=Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "#webpage=urlopen(req).read()\n",
    "#page_soup = soup(webpage, \"html.parser\")\n",
    "#a=extract_description(page_soup)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
