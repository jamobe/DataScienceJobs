{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import os.path\n",
    "\n",
    "path = os.getcwd()\n",
    "parent_folder, current_folder = os.path.split(path)\n",
    "\n",
    "data = defaultdict(list)\n",
    "data['location'] = ['Frankfurt','Berlin','Bern','Zurich','Amsterdam','Wien','Munich','Barcelona','Paris','Aurich','Den Haag','Warsaw']\n",
    "data['region'] = ['Hessen','Berlin','Bern','Zurich','North Holland','Wien','Bayern','Barcelona','Ile-de-France','Niedersachsen','South Holland','Masovia']\n",
    "data['country'] = ['Germany','Germany','Switzerland','Switzerland','Netherlands','Austria','Germany','Spain','France','Germany','Netherlands','Poland']\n",
    "loc2 = pd.DataFrame(data)\n",
    "\n",
    "loc2 = loc2.append({'location' : 'Dusseldorf' , 'region' : 'Nordrhein-Westfalen', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Düsseldorf' , 'region' : 'Nordrhein-Westfalen', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Bonn' , 'region' : 'Nordrhein-Westfalen', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Stuttgart' , 'region' : 'Baden-Württemberg', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Vilnius' , 'region' : 'Vilnius', 'country':'Lithuania'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Dublin' , 'region' : 'Leinster', 'country':'Ireland'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Wynyard' , 'region' : 'Tasmania', 'country':'Australia'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Eindhoven' , 'region' : 'North Brabant', 'country':'Netherlands'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Melbourne' , 'region' : 'Victoria', 'country':'Australia'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Haeren' , 'region' : 'Brussels', 'country':'Belgium'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Hamburg' , 'region' : 'Hamburg', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'München' , 'region' : 'Bayern', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Köln' , 'region' : 'Nordrhein-Westfalen', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Potsdam' , 'region' : 'Brandenburg', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Leipzig' , 'region' : 'Sachsen', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Dresden' , 'region' : 'Sachsen', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Karlsruhe' , 'region' : 'Baden-Württemberg', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Hannover' , 'region' : 'Niedersachsen', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Nürnberg' , 'region' : 'Bayern', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Freiburg' , 'region' : 'Baden-Württemberg', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Essen' , 'region' : 'Nordrhein-Westfalen', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Mannheim' , 'region' : 'Baden-Württemberg', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Ludwigshafen Am Rhein' , 'region' : 'Rheinland-Pfalz', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Bremen' , 'region' : 'Bremen', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Friedrichshafen' , 'region' : 'Baden-Württemberg', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Erlangen' , 'region' : 'Bayern', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Wolfsburg' , 'region' : 'Niedersachsen', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Aachen' , 'region' : 'Nordrhein-Westfalen', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Teterow' , 'region' : 'Mecklenburg-Vorpommern', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Penzberg' , 'region' : 'Bayern', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Dortmund' , 'region' : 'Nordrhein-Westfalen', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Bad Homburg Vor Der Höhe' , 'region' : 'Hessen', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Wiesbaden' , 'region' : 'Hessen', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Rostock' , 'region' : 'Mecklenburg-Vorpommern', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Teltow' , 'region' : 'Brandenburg', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Biberach An Der Riß' , 'region' : 'Baden-Württemberg', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Ingolstadt' , 'region' : 'Bayern', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Saarbrücken' , 'region' : 'Saarland', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Böblingen' , 'region' : 'Baden-Württemberg', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Münster' , 'region' : 'Nordrhein-Westfalen', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Raunheim' , 'region' : 'Hessen', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Schönefeld' , 'region' : 'Brandenburg', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Ismaning' , 'region' : 'Bayern', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Münchberg' , 'region' : 'Bayern', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Magdeburg' , 'region' : 'Sachsen-Anhalt', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Immenstadt Im Allgäu' , 'region' : 'Bayern', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Eschborn' , 'region' : 'Hessen', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Landshut' , 'region' : 'Bayern', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Einbeck' , 'region' : 'Niedersachsen', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Herzogenaurach' , 'region' : 'Bayern', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Stade' , 'region' : 'Niedersachsen', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Heidelberg' , 'region' : 'Baden-Württemberg', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Lörrach' , 'region' : 'Baden-Württemberg', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Pforzheim' , 'region' : 'Baden-Württemberg', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Ludwigsburg' , 'region' : 'Baden-Württemberg', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Ulm' , 'region' : 'Baden-Württemberg', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Konstanz' , 'region' : 'Baden-Württemberg', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Baden-Württemberg' , 'region' : 'Baden-Württemberg', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Bühl' , 'region' : 'Baden-Württemberg', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Inning Am Ammersee' , 'region' : 'Bayern', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Wangen Im Allgäu' , 'region' : 'Baden-Württemberg', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Heidenheim An Der Brenz' , 'region' : 'Baden-Württemberg', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Trostberg An Der Alz' , 'region' : 'Bayern', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Kaiserslautern' , 'region' : 'Rheinland-Pfalz', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Wörth Am Rhein' , 'region' : 'Rheinland-Pfalz', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Waldbronn' , 'region' : 'Baden-Württemberg', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Limburg An Der Lahn' , 'region' : 'Hessen', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Göttingen' , 'region' : 'Niedersachsen', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Bochum' , 'region' : 'Nordrhein-Westfalen', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Wuppertal' , 'region' : 'Nordrhein-Westfalen', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Paderborn' , 'region' : 'Nordrhein-Westfalen', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Meerbusch' , 'region' : 'Nordrhein-Westfalen', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Leverkusen' , 'region' : 'Nordrhein-Westfalen', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Nordrhein-Westfalen' , 'region' : 'Nordrhein-Westfalen', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Hürth' , 'region' : 'Nordrhein-Westfalen', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Maulburg' , 'region' : 'Baden-Württemberg', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Türkheim' , 'region' : 'Bayern', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Bayreuth' , 'region' : 'Bayern', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Aschheim' , 'region' : 'Bayern', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Badenweiler' , 'region' : 'Baden-Württemberg', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Abstatt' , 'region' : 'Baden-Württemberg', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Calbe' , 'region' : 'Sachsen-Anhalt', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Coswig' , 'region' : 'Sachsen', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Halle (Saale)' , 'region' : 'Sachsen-Anhalt', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Jena' , 'region' : 'Thüringen', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Salzgitter' , 'region' : 'Niedersachsen', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Bielefeld' , 'region' : 'Nordrhein-Westfalen', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Brandenburg' , 'region' : 'Brandenburg', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Schleswig-Holstein' , 'region' : 'Schleswig-Holstein', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Kiel' , 'region' : 'Schleswig-Holstein', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Deutschland' , 'region' : '', 'country':'Germany'} , ignore_index=True)\n",
    "loc2 = loc2.append({'location' : 'Hennigsdorf' , 'region' : 'Brandenburg', 'country':'Germany'} , ignore_index=True)\n",
    "\n",
    "\n",
    "loc2.to_csv(parent_folder+'/data/locations.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 2585, saw 2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-6ca58ad0f56f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_folder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/data/plz_de.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#loc2.to_csv(parent_folder+'/data/plz_de2.csv',index=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dsj/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dsj/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dsj/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dsj/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2057\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 2585, saw 2\n"
     ]
    }
   ],
   "source": [
    "loc2 = pd.read_csv(parent_folder+'/data/plz_de.csv')\n",
    "\n",
    "#loc2.to_csv(parent_folder+'/data/plz_de2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "path = os.getcwd()\n",
    "parent_folder, current_folder = os.path.split(path)\n",
    "\n",
    "csv_path = '/data/indeed_de_all.csv'\n",
    "#csv_path = '/data/indeed_us_all.csv'\n",
    "#csv_path = '/data/monster_all.csv'\n",
    "\n",
    "df = pd.read_csv(parent_folder + csv_path, sep='\\t')\n",
    "df = df.replace(np.NaN, 'NaN')\n",
    "df['salary'] = df['salary'].astype(str)\n",
    "#df = df.replace('Not available',np.NaN)\n",
    "df.to_csv(parent_folder + csv_path, sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jamoth/DSR/DataScienceJobs'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary</th>\n",
       "      <th>location</th>\n",
       "      <th>duration</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>extraction_date</th>\n",
       "      <th>salary_low</th>\n",
       "      <th>salary_high</th>\n",
       "      <th>jobtype</th>\n",
       "      <th>industry</th>\n",
       "      <th>education</th>\n",
       "      <th>career</th>\n",
       "      <th>ref_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UNICEPTA GmbH</td>\n",
       "      <td>Data Analyst (m/w/d) Analytics &amp; Insights in K...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Deine Aufgaben:\\nMit Deiner Arbeit bist Du m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-10-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Analytics Academy - The Information Lab Deutsc...</td>\n",
       "      <td>Analytics Academy - Junior Data Analyst, m/w/d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Die Analytics Academy– dein Karriere-Sprungb...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-10-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IAV GmbH</td>\n",
       "      <td>Solution Architect* – Plattform Big Data &amp; IoT...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Ihre Aufgaben\\nZur Absicherung der Entwicklu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-10-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Marc O'Polo</td>\n",
       "      <td>(Junior) Data Warehouse Developer / (Junior) D...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Deine Aufgaben\\nAnalyse und Debugging komple...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-10-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>etone Motion Analysis GmbH</td>\n",
       "      <td>Senior Data Analyst (m/f/d)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vor 2 Tagen</td>\n",
       "      <td>[\"Stealth Fitness Tech Startup with great fund...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-10-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18931</th>\n",
       "      <td>gamigo group</td>\n",
       "      <td>Data Engineering Team Lead (m/f/d) – Berlin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>vor 3 Tagen</td>\n",
       "      <td>['We are looking for a skilled and experienced...</td>\n",
       "      <td>https://de.indeed.com/company/gamigo-group/job...</td>\n",
       "      <td>2019-11-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18932</th>\n",
       "      <td>Hanseatic Statistics</td>\n",
       "      <td>Data Analyst (m/w/d)</td>\n",
       "      <td>27 € pro Stunde</td>\n",
       "      <td>Hannover</td>\n",
       "      <td>Vor mehr als 30 Tagen</td>\n",
       "      <td>['Hi,wir suchen Verstärkung für unser Team, be...</td>\n",
       "      <td>https://de.indeed.com/company/Hanseatic-Statis...</td>\n",
       "      <td>2019-11-04</td>\n",
       "      <td>27 € pro Stunde</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18933</th>\n",
       "      <td>Küchen Quelle GmbH</td>\n",
       "      <td>Data Scientist m/w/d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Vor mehr als 30 Tagen</td>\n",
       "      <td>['Du bist ein Anders-Denker, Ideen-Haber und W...</td>\n",
       "      <td>https://de.indeed.com/rc/clk?jk=575179108c89ba...</td>\n",
       "      <td>2019-11-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18934</th>\n",
       "      <td>Analytics Academy - The Information Lab Deutsc...</td>\n",
       "      <td>Analytics Academy - Junior Data Analyst, m/w/d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Die Analytics Academy– dein Karriere-Sprungb...</td>\n",
       "      <td>https://de.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>2019-11-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18935</th>\n",
       "      <td>MDM Münzhandelsgesellschaft mbH &amp; Co. KG Deuts...</td>\n",
       "      <td>Junior Data Warehouse Entwickler (m/w/d)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Du hast eine Affinität zu Daten und Analysen...</td>\n",
       "      <td>https://de.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>2019-11-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18936 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 company  \\\n",
       "0                                          UNICEPTA GmbH   \n",
       "1      Analytics Academy - The Information Lab Deutsc...   \n",
       "2                                               IAV GmbH   \n",
       "3                                            Marc O'Polo   \n",
       "4                             etone Motion Analysis GmbH   \n",
       "...                                                  ...   \n",
       "18931                                       gamigo group   \n",
       "18932                               Hanseatic Statistics   \n",
       "18933                                 Küchen Quelle GmbH   \n",
       "18934  Analytics Academy - The Information Lab Deutsc...   \n",
       "18935  MDM Münzhandelsgesellschaft mbH & Co. KG Deuts...   \n",
       "\n",
       "                                               job_title           salary  \\\n",
       "0      Data Analyst (m/w/d) Analytics & Insights in K...              NaN   \n",
       "1         Analytics Academy - Junior Data Analyst, m/w/d              NaN   \n",
       "2      Solution Architect* – Plattform Big Data & IoT...              NaN   \n",
       "3      (Junior) Data Warehouse Developer / (Junior) D...              NaN   \n",
       "4                            Senior Data Analyst (m/f/d)              NaN   \n",
       "...                                                  ...              ...   \n",
       "18931        Data Engineering Team Lead (m/f/d) – Berlin              NaN   \n",
       "18932                               Data Analyst (m/w/d)  27 € pro Stunde   \n",
       "18933                               Data Scientist m/w/d              NaN   \n",
       "18934     Analytics Academy - Junior Data Analyst, m/w/d              NaN   \n",
       "18935           Junior Data Warehouse Entwickler (m/w/d)              NaN   \n",
       "\n",
       "       location               duration  \\\n",
       "0           NaN                    NaN   \n",
       "1           NaN                    NaN   \n",
       "2           NaN                    NaN   \n",
       "3           NaN                    NaN   \n",
       "4           NaN            vor 2 Tagen   \n",
       "...         ...                    ...   \n",
       "18931    Berlin            vor 3 Tagen   \n",
       "18932  Hannover  Vor mehr als 30 Tagen   \n",
       "18933    Berlin  Vor mehr als 30 Tagen   \n",
       "18934       NaN                    NaN   \n",
       "18935       NaN                    NaN   \n",
       "\n",
       "                                             description  \\\n",
       "0      ['Deine Aufgaben:\\nMit Deiner Arbeit bist Du m...   \n",
       "1      ['Die Analytics Academy– dein Karriere-Sprungb...   \n",
       "2      ['Ihre Aufgaben\\nZur Absicherung der Entwicklu...   \n",
       "3      ['Deine Aufgaben\\nAnalyse und Debugging komple...   \n",
       "4      [\"Stealth Fitness Tech Startup with great fund...   \n",
       "...                                                  ...   \n",
       "18931  ['We are looking for a skilled and experienced...   \n",
       "18932  ['Hi,wir suchen Verstärkung für unser Team, be...   \n",
       "18933  ['Du bist ein Anders-Denker, Ideen-Haber und W...   \n",
       "18934  ['Die Analytics Academy– dein Karriere-Sprungb...   \n",
       "18935  ['Du hast eine Affinität zu Daten und Analysen...   \n",
       "\n",
       "                                                     url extraction_date  \\\n",
       "0                                                    NaN      2019-10-24   \n",
       "1                                                    NaN      2019-10-24   \n",
       "2                                                    NaN      2019-10-24   \n",
       "3                                                    NaN      2019-10-24   \n",
       "4                                                    NaN      2019-10-24   \n",
       "...                                                  ...             ...   \n",
       "18931  https://de.indeed.com/company/gamigo-group/job...      2019-11-04   \n",
       "18932  https://de.indeed.com/company/Hanseatic-Statis...      2019-11-04   \n",
       "18933  https://de.indeed.com/rc/clk?jk=575179108c89ba...      2019-11-04   \n",
       "18934  https://de.indeed.com/pagead/clk?mo=r&ad=-6NYl...      2019-11-04   \n",
       "18935  https://de.indeed.com/pagead/clk?mo=r&ad=-6NYl...      2019-11-04   \n",
       "\n",
       "            salary_low salary_high  jobtype  industry  education  career  \\\n",
       "0                  NaN         NaN      NaN       NaN        NaN     NaN   \n",
       "1                  NaN         NaN      NaN       NaN        NaN     NaN   \n",
       "2                  NaN         NaN      NaN       NaN        NaN     NaN   \n",
       "3                  NaN         NaN      NaN       NaN        NaN     NaN   \n",
       "4                  NaN         NaN      NaN       NaN        NaN     NaN   \n",
       "...                ...         ...      ...       ...        ...     ...   \n",
       "18931              NaN         NaN      NaN       NaN        NaN     NaN   \n",
       "18932  27 € pro Stunde         NaN      NaN       NaN        NaN     NaN   \n",
       "18933              NaN         NaN      NaN       NaN        NaN     NaN   \n",
       "18934              NaN         NaN      NaN       NaN        NaN     NaN   \n",
       "18935              NaN         NaN      NaN       NaN        NaN     NaN   \n",
       "\n",
       "       ref_code  \n",
       "0           NaN  \n",
       "1           NaN  \n",
       "2           NaN  \n",
       "3           NaN  \n",
       "4           NaN  \n",
       "...         ...  \n",
       "18931       NaN  \n",
       "18932       NaN  \n",
       "18933       NaN  \n",
       "18934       NaN  \n",
       "18935       NaN  \n",
       "\n",
       "[18936 rows x 15 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary</th>\n",
       "      <th>location</th>\n",
       "      <th>duration</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>extraction_date</th>\n",
       "      <th>salary_low</th>\n",
       "      <th>salary_high</th>\n",
       "      <th>jobtype</th>\n",
       "      <th>industry</th>\n",
       "      <th>education</th>\n",
       "      <th>career</th>\n",
       "      <th>ref_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DoScouting</td>\n",
       "      <td>Football Data Journalist</td>\n",
       "      <td>20 € - 25 € pro Stunde</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>vor 22 Stunden</td>\n",
       "      <td>[\"URGENT!! Looking for sport data journalists ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-10-24</td>\n",
       "      <td>20 €</td>\n",
       "      <td>25 € pro Stunde</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hanseatic Statistics</td>\n",
       "      <td>Data Analyst (m/w/d)</td>\n",
       "      <td>27 € pro Stunde</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>vor 30+ Tagen</td>\n",
       "      <td>['Hi,wir suchen Verstärkung für unser Team, be...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-10-24</td>\n",
       "      <td>27 € pro Stunde</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>idalab GmbH</td>\n",
       "      <td>Working Student Data Science (m/f/d)</td>\n",
       "      <td>15 € pro Stunde</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>vor 6 Monaten</td>\n",
       "      <td>['Wer wir sind\\nAls Spezialist*innen für künst...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-10-24</td>\n",
       "      <td>15 € pro Stunde</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>idalab GmbH</td>\n",
       "      <td>Working Student Data Science (m/f/d)</td>\n",
       "      <td>15 € pro Stunde</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>vor 6 Monaten</td>\n",
       "      <td>['Wer wir sind\\nAls Spezialist*innen für künst...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-10-24</td>\n",
       "      <td>15 € pro Stunde</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Haensel AMS GmbH</td>\n",
       "      <td>DevOps/ Data Engineer Werksstudent / Working S...</td>\n",
       "      <td>850 € pro Monat</td>\n",
       "      <td>Berlin-Kreuzberg</td>\n",
       "      <td>vor 27 Tagen</td>\n",
       "      <td>['We at Haensel AMS – Advanced Mathematical So...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-10-24</td>\n",
       "      <td>850 € pro Monat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18898</th>\n",
       "      <td>Hanseatic Statistics</td>\n",
       "      <td>Data Analyst (m/w/d)</td>\n",
       "      <td>27 € pro Stunde</td>\n",
       "      <td>Hannover</td>\n",
       "      <td>Vor mehr als 30 Tagen</td>\n",
       "      <td>['Hi,wir suchen Verstärkung für unser Team, be...</td>\n",
       "      <td>https://de.indeed.com/company/Hanseatic-Statis...</td>\n",
       "      <td>2019-11-04</td>\n",
       "      <td>27 € pro Stunde</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18910</th>\n",
       "      <td>Zero to One Search</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>55.000 € - 90.000 € pro Jahr</td>\n",
       "      <td>Stuttgart</td>\n",
       "      <td>vor 12 Tagen</td>\n",
       "      <td>[\"Join a German dynamic global technology comp...</td>\n",
       "      <td>https://de.indeed.com/company/Zero-to-One-Sear...</td>\n",
       "      <td>2019-11-04</td>\n",
       "      <td>55.000 €</td>\n",
       "      <td>90.000 € pro Jahr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18915</th>\n",
       "      <td>Hanseatic Statistics</td>\n",
       "      <td>Data Analyst (m/w/d)</td>\n",
       "      <td>27 € pro Stunde</td>\n",
       "      <td>Hannover</td>\n",
       "      <td>Vor mehr als 30 Tagen</td>\n",
       "      <td>['Hi,wir suchen Verstärkung für unser Team, be...</td>\n",
       "      <td>https://de.indeed.com/company/Hanseatic-Statis...</td>\n",
       "      <td>2019-11-04</td>\n",
       "      <td>27 € pro Stunde</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18927</th>\n",
       "      <td>Zero to One Search</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>55.000 € - 90.000 € pro Jahr</td>\n",
       "      <td>Stuttgart</td>\n",
       "      <td>vor 12 Tagen</td>\n",
       "      <td>[\"Join a German dynamic global technology comp...</td>\n",
       "      <td>https://de.indeed.com/company/Zero-to-One-Sear...</td>\n",
       "      <td>2019-11-04</td>\n",
       "      <td>55.000 €</td>\n",
       "      <td>90.000 € pro Jahr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18932</th>\n",
       "      <td>Hanseatic Statistics</td>\n",
       "      <td>Data Analyst (m/w/d)</td>\n",
       "      <td>27 € pro Stunde</td>\n",
       "      <td>Hannover</td>\n",
       "      <td>Vor mehr als 30 Tagen</td>\n",
       "      <td>['Hi,wir suchen Verstärkung für unser Team, be...</td>\n",
       "      <td>https://de.indeed.com/company/Hanseatic-Statis...</td>\n",
       "      <td>2019-11-04</td>\n",
       "      <td>27 € pro Stunde</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1055 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    company  \\\n",
       "7                DoScouting   \n",
       "11     Hanseatic Statistics   \n",
       "24              idalab GmbH   \n",
       "39              idalab GmbH   \n",
       "43         Haensel AMS GmbH   \n",
       "...                     ...   \n",
       "18898  Hanseatic Statistics   \n",
       "18910    Zero to One Search   \n",
       "18915  Hanseatic Statistics   \n",
       "18927    Zero to One Search   \n",
       "18932  Hanseatic Statistics   \n",
       "\n",
       "                                               job_title  \\\n",
       "7                               Football Data Journalist   \n",
       "11                                  Data Analyst (m/w/d)   \n",
       "24                  Working Student Data Science (m/f/d)   \n",
       "39                  Working Student Data Science (m/f/d)   \n",
       "43     DevOps/ Data Engineer Werksstudent / Working S...   \n",
       "...                                                  ...   \n",
       "18898                               Data Analyst (m/w/d)   \n",
       "18910                                      Data Engineer   \n",
       "18915                               Data Analyst (m/w/d)   \n",
       "18927                                      Data Engineer   \n",
       "18932                               Data Analyst (m/w/d)   \n",
       "\n",
       "                             salary          location               duration  \\\n",
       "7            20 € - 25 € pro Stunde            Berlin         vor 22 Stunden   \n",
       "11                  27 € pro Stunde            Berlin          vor 30+ Tagen   \n",
       "24                  15 € pro Stunde            Berlin          vor 6 Monaten   \n",
       "39                  15 € pro Stunde            Berlin          vor 6 Monaten   \n",
       "43                  850 € pro Monat  Berlin-Kreuzberg           vor 27 Tagen   \n",
       "...                             ...               ...                    ...   \n",
       "18898               27 € pro Stunde          Hannover  Vor mehr als 30 Tagen   \n",
       "18910  55.000 € - 90.000 € pro Jahr         Stuttgart           vor 12 Tagen   \n",
       "18915               27 € pro Stunde          Hannover  Vor mehr als 30 Tagen   \n",
       "18927  55.000 € - 90.000 € pro Jahr         Stuttgart           vor 12 Tagen   \n",
       "18932               27 € pro Stunde          Hannover  Vor mehr als 30 Tagen   \n",
       "\n",
       "                                             description  \\\n",
       "7      [\"URGENT!! Looking for sport data journalists ...   \n",
       "11     ['Hi,wir suchen Verstärkung für unser Team, be...   \n",
       "24     ['Wer wir sind\\nAls Spezialist*innen für künst...   \n",
       "39     ['Wer wir sind\\nAls Spezialist*innen für künst...   \n",
       "43     ['We at Haensel AMS – Advanced Mathematical So...   \n",
       "...                                                  ...   \n",
       "18898  ['Hi,wir suchen Verstärkung für unser Team, be...   \n",
       "18910  [\"Join a German dynamic global technology comp...   \n",
       "18915  ['Hi,wir suchen Verstärkung für unser Team, be...   \n",
       "18927  [\"Join a German dynamic global technology comp...   \n",
       "18932  ['Hi,wir suchen Verstärkung für unser Team, be...   \n",
       "\n",
       "                                                     url extraction_date  \\\n",
       "7                                                    NaN      2019-10-24   \n",
       "11                                                   NaN      2019-10-24   \n",
       "24                                                   NaN      2019-10-24   \n",
       "39                                                   NaN      2019-10-24   \n",
       "43                                                   NaN      2019-10-24   \n",
       "...                                                  ...             ...   \n",
       "18898  https://de.indeed.com/company/Hanseatic-Statis...      2019-11-04   \n",
       "18910  https://de.indeed.com/company/Zero-to-One-Sear...      2019-11-04   \n",
       "18915  https://de.indeed.com/company/Hanseatic-Statis...      2019-11-04   \n",
       "18927  https://de.indeed.com/company/Zero-to-One-Sear...      2019-11-04   \n",
       "18932  https://de.indeed.com/company/Hanseatic-Statis...      2019-11-04   \n",
       "\n",
       "            salary_low         salary_high  jobtype  industry  education  \\\n",
       "7                20 €      25 € pro Stunde      NaN       NaN        NaN   \n",
       "11     27 € pro Stunde                 NaN      NaN       NaN        NaN   \n",
       "24     15 € pro Stunde                 NaN      NaN       NaN        NaN   \n",
       "39     15 € pro Stunde                 NaN      NaN       NaN        NaN   \n",
       "43     850 € pro Monat                 NaN      NaN       NaN        NaN   \n",
       "...                ...                 ...      ...       ...        ...   \n",
       "18898  27 € pro Stunde                 NaN      NaN       NaN        NaN   \n",
       "18910        55.000 €    90.000 € pro Jahr      NaN       NaN        NaN   \n",
       "18915  27 € pro Stunde                 NaN      NaN       NaN        NaN   \n",
       "18927        55.000 €    90.000 € pro Jahr      NaN       NaN        NaN   \n",
       "18932  27 € pro Stunde                 NaN      NaN       NaN        NaN   \n",
       "\n",
       "       career  ref_code  \n",
       "7         NaN       NaN  \n",
       "11        NaN       NaN  \n",
       "24        NaN       NaN  \n",
       "39        NaN       NaN  \n",
       "43        NaN       NaN  \n",
       "...       ...       ...  \n",
       "18898     NaN       NaN  \n",
       "18910     NaN       NaN  \n",
       "18915     NaN       NaN  \n",
       "18927     NaN       NaN  \n",
       "18932     NaN       NaN  \n",
       "\n",
       "[1055 rows x 15 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(subset =['salary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
