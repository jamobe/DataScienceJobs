{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for cleaning data from Harham.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, bs4, time\n",
    "import pandas as pd\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from datetime import date\n",
    "from langdetect import detect\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import cleaning_funcs_harnham as cf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\lundr\\\\DSJ\\\\DataScienceJobs\\\\Cleaning'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n",
    "#os.chdir('Cleaning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RAW_harnham_usa_2019-12-03.pkl',\n",
       " 'RAW_harnham_ger_2019-12-03.pkl',\n",
       " 'RAW_harnham_ger_2019-12-13.pkl',\n",
       " 'RAW_harnham_usa_2019-12-13.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir('C:/Users/lundr/DataScienceJobs/data/harnham_raw_pickles/')\n",
    "files = ['RAW_harnham_usa_2019-12-03.pkl','RAW_harnham_ger_2019-12-03.pkl','RAW_harnham_ger_2019-12-13.pkl','RAW_harnham_usa_2019-12-13.pkl']\n",
    "files\n",
    "# if there are checkpoints in the folder these will need t be deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "info = pd.DataFrame(columns = [\"job_ref\",\"job_title\",\"location\",\"salary\",\"description\",\"type\",\"country\",\"extraction_date\",\"url\"])\n",
    "\n",
    "import os\n",
    "\n",
    "for i in files:\n",
    "    \n",
    "    read_in = pd.read_pickle(\"C:/Users/lundr/DataScienceJobs/data/harnham_raw_pickles/\"+i)\n",
    "    read_in['salary_low'], read_in['salary_high'], read_in['salary_type'] = cf.create_split_salary_range(read_in['salary'])\n",
    "    if read_in['country'][0] == 'UK':\n",
    "        read_in['salary_low'] =cf.clean_salary(read_in['salary_low'],\"£\")\n",
    "        read_in['salary_high'] =cf.clean_salary(read_in['salary_high'],\"£\")\n",
    "    elif read_in['country'][0] == 'USA':   \n",
    "        read_in['salary_low'] = cf.clean_salary(read_in['salary_low'],\"$\")\n",
    "        read_in['salary_high'] = cf.clean_salary(read_in['salary_high'],\"$\")\n",
    "    elif read_in['country'][0] == 'GER':   \n",
    "        read_in['salary_low'] = cf.clean_salary(read_in['salary_low'],\"€\")\n",
    "        read_in['salary_high'] = cf.clean_salary(read_in['salary_high'],\"€\")\n",
    "    else:\n",
    "        pass\n",
    "    info = pd.concat([info,read_in],ignore_index = True, axis = 0, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           New York\n",
       "1         California\n",
       "2           New York\n",
       "3           New York\n",
       "4      Massachusetts\n",
       "           ...      \n",
       "638         New York\n",
       "639         New York\n",
       "640       California\n",
       "641         New York\n",
       "642    Massachusetts\n",
       "Name: Region, Length: 643, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info['Region']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows with identical descriptions\n",
    "info = info.drop_duplicates(['description'])\n",
    "\n",
    "#reset index after dropping duplicated\n",
    "info.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lundr\\DSJ\\DataScienceJobs\\Cleaning\\cleaning_funcs_harnham.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  a[j] = l.replace(l_2,\" \")\n",
      "C:\\Users\\lundr\\DSJ\\DataScienceJobs\\Cleaning\\cleaning_funcs_harnham.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if type(a[i])!=\"str\":a[i]=str(a[i])\n",
      "C:\\Users\\lundr\\DSJ\\DataScienceJobs\\Cleaning\\cleaning_funcs_harnham.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  a[i]=(pattern.sub(lambda m: rep[re.escape(m.group(0))],a[i]))\n"
     ]
    }
   ],
   "source": [
    "# run data cleaning functions\n",
    "info['description']=cf.remove_duped_info(info['description'],[info['job_title'],info['location']])\n",
    "info['description']=cf.clean_column(info['description'])\n",
    "info['location']=cf.clean_column(info['location'])\n",
    "info['ref_code'] = cf.clean_jobref(info['job_ref'])\n",
    "info['Region'] = cf.check_locations(info['location'],info['country'])\n",
    "info['salary_type']=cf.clean_salary_type(info['salary_type'])\n",
    "country_dict = {'UK':'UK','USA':'USA','GER':'Germany','Germany':'Germany'}\n",
    "info['country']=info['country'].map(country_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "info['Region'] = [x.split(\",\")[0] for x in info['Region']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "corrections = {\"Bromley Kent\" : \"South East\",\n",
    "               \"South West England\" : \"South West\",\n",
    "               \"Rochester New York\" : \"NY\",\n",
    "               \"Toronto  Ontario\" : \"Canada\",\n",
    "               \"Augsburg  Bayern\" : \"Bayern\",\n",
    "               \"District of Columbia\" : \"WA\",\n",
    "               \"Perth & Kinross\" : \"Scotland\"\n",
    "               \n",
    "    \n",
    "}\n",
    "#Bromley Kent = South East\n",
    "# South East London London = 'London'\n",
    "#England,South West,South West = South West\n",
    "#\"Rochester New York\" = \"NY\"\n",
    "# Toronto Ontario = CAN [Country] *Region = Canada\n",
    "#augsberg bayern = \n",
    "#District of colombia = \n",
    "#Perth & kinross = Scotland\n",
    "     \n",
    "     \n",
    "#for i in range(len(info['location'])):\n",
    "for i in range(len(info['location'])):\n",
    "    if info['location'][i].lstrip().rstrip() in corrections.keys():\n",
    "        info['Region'][i] = corrections[info['location'][i].lstrip().rstrip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add correct column headings and new columns\n",
    "\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "#info.columns = ['ref_code', 'job_title', 'location', 'salary', 'description', 'jobtype','url',\n",
    "#       'salary_low', 'salary_high']\n",
    "\n",
    "#company: Company or recruiter advertising the job\n",
    "info['company'] = 'Harnham'\n",
    "\n",
    "\n",
    "#duration: How long the job had been advertised for at time of scraping\n",
    "info['posted_date'] = np.nan\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lundr\\AppData\\Local\\Continuum\\anaconda3\\envs\\dsj3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\lundr\\AppData\\Local\\Continuum\\anaconda3\\envs\\dsj3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\lundr\\AppData\\Local\\Continuum\\anaconda3\\envs\\dsj3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\lundr\\AppData\\Local\\Continuum\\anaconda3\\envs\\dsj3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\lundr\\AppData\\Local\\Continuum\\anaconda3\\envs\\dsj3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "C:\\Users\\lundr\\AppData\\Local\\Continuum\\anaconda3\\envs\\dsj3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\lundr\\AppData\\Local\\Continuum\\anaconda3\\envs\\dsj3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\lundr\\AppData\\Local\\Continuum\\anaconda3\\envs\\dsj3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\lundr\\AppData\\Local\\Continuum\\anaconda3\\envs\\dsj3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "C:\\Users\\lundr\\AppData\\Local\\Continuum\\anaconda3\\envs\\dsj3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\lundr\\AppData\\Local\\Continuum\\anaconda3\\envs\\dsj3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\lundr\\AppData\\Local\\Continuum\\anaconda3\\envs\\dsj3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\lundr\\AppData\\Local\\Continuum\\anaconda3\\envs\\dsj3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\lundr\\AppData\\Local\\Continuum\\anaconda3\\envs\\dsj3\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\lundr\\AppData\\Local\\Continuum\\anaconda3\\envs\\dsj3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\lundr\\AppData\\Local\\Continuum\\anaconda3\\envs\\dsj3\\lib\\site-packages\\ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\lundr\\AppData\\Local\\Continuum\\anaconda3\\envs\\dsj3\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\lundr\\AppData\\Local\\Continuum\\anaconda3\\envs\\dsj3\\lib\\site-packages\\ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>extraction_date</th>\n",
       "      <th>job_ref</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_high</th>\n",
       "      <th>salary_low</th>\n",
       "      <th>salary_type</th>\n",
       "      <th>type</th>\n",
       "      <th>url</th>\n",
       "      <th>ref_code</th>\n",
       "      <th>Region</th>\n",
       "      <th>company</th>\n",
       "      <th>posted_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index, country, description, extraction_date, job_ref, job_title, location, salary, salary_high, salary_low, salary_type, type, url, ref_code, Region, company, posted_date]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "info['salary_low'][131]  = 110000\n",
    "info['salary_high'][131]  = 130000\n",
    "\n",
    "info['salary_low'][306]  = 100000\n",
    "info['salary_high'][306]  = 11000\n",
    "\n",
    "info['salary_low'][360]  = 165000\n",
    "info['salary_high'][360]  = 195000\n",
    "\n",
    "info['salary_low'][365]  = 150000\n",
    "info['salary_high'][365]  = 170000\n",
    "\n",
    "info['salary_low'][407]  = 110000\n",
    "info['salary_high'][407]  = 110000\n",
    "\n",
    "info['salary_low'][432]  = 160000\n",
    "info['salary_high'][432]  = 220000\n",
    "\n",
    "info['salary_low'][475]  = 60000\n",
    "info['salary_high'][475]  = 75000\n",
    "\n",
    "info['salary_low'][477]  = 55000\n",
    "info['salary_high'][477]  = 65000\n",
    "\n",
    "info['salary_low'][582]  = 170000\n",
    "info['salary_high'][582]  = 190000\n",
    "\n",
    "info[(info['salary_type']=='yearly') & (info['salary_low'] < 20000)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>extraction_date</th>\n",
       "      <th>job_ref</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_high</th>\n",
       "      <th>salary_low</th>\n",
       "      <th>salary_type</th>\n",
       "      <th>type</th>\n",
       "      <th>url</th>\n",
       "      <th>ref_code</th>\n",
       "      <th>Region</th>\n",
       "      <th>company</th>\n",
       "      <th>posted_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>404</td>\n",
       "      <td>USA</td>\n",
       "      <td>' minneapolis$220,000 ', \"a global automotive...</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>[23423/SN]</td>\n",
       "      <td>VP of Engineering</td>\n",
       "      <td>'Minneapolis, Minnesota'</td>\n",
       "      <td>US$24385 - US$268235 per annum + Benefits</td>\n",
       "      <td>268235.0</td>\n",
       "      <td>24385.0</td>\n",
       "      <td>yearly</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>/job/vp-of-engineering-in-minneapolis-minnesot...</td>\n",
       "      <td>23423/SN</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>Harnham</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>466</td>\n",
       "      <td>Germany</td>\n",
       "      <td>'lead data scientist (m/f/d)90.000 - 100.000€...</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>[67268/TS]</td>\n",
       "      <td>4MAT</td>\n",
       "      <td>'Münster, Nordrhein-Westfalen'</td>\n",
       "      <td>€90000 - €1000000 per annum</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>yearly</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>https://www.harnham.com/job/lead-data-scientis...</td>\n",
       "      <td>67268/TS</td>\n",
       "      <td>Nordrhein-Westfalen</td>\n",
       "      <td>Harnham</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>1060</td>\n",
       "      <td>USA</td>\n",
       "      <td>'this company is looking for a very strong en...</td>\n",
       "      <td>2019-12-13</td>\n",
       "      <td>[EMC]</td>\n",
       "      <td>4MAT</td>\n",
       "      <td>'San Francisco, California'</td>\n",
       "      <td>US$25604 - US$231657 per annum</td>\n",
       "      <td>231657.0</td>\n",
       "      <td>25604.0</td>\n",
       "      <td>yearly</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>/job/engineering-manager-in-san-francisco-cali...</td>\n",
       "      <td>EMC</td>\n",
       "      <td>California</td>\n",
       "      <td>Harnham</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  country                                        description  \\\n",
       "396    404      USA   ' minneapolis$220,000 ', \"a global automotive...   \n",
       "457    466  Germany   'lead data scientist (m/f/d)90.000 - 100.000€...   \n",
       "634   1060      USA   'this company is looking for a very strong en...   \n",
       "\n",
       "    extraction_date     job_ref          job_title  \\\n",
       "396      2019-12-03  [23423/SN]  VP of Engineering   \n",
       "457      2019-12-03  [67268/TS]               4MAT   \n",
       "634      2019-12-13       [EMC]               4MAT   \n",
       "\n",
       "                             location  \\\n",
       "396         'Minneapolis, Minnesota'    \n",
       "457   'Münster, Nordrhein-Westfalen'    \n",
       "634      'San Francisco, California'    \n",
       "\n",
       "                                        salary  salary_high  salary_low  \\\n",
       "396  US$24385 - US$268235 per annum + Benefits     268235.0     24385.0   \n",
       "457                €90000 - €1000000 per annum    1000000.0     90000.0   \n",
       "634             US$25604 - US$231657 per annum     231657.0     25604.0   \n",
       "\n",
       "    salary_type       type                                                url  \\\n",
       "396      yearly  Permanent  /job/vp-of-engineering-in-minneapolis-minnesot...   \n",
       "457      yearly  Permanent  https://www.harnham.com/job/lead-data-scientis...   \n",
       "634      yearly  Permanent  /job/engineering-manager-in-san-francisco-cali...   \n",
       "\n",
       "     ref_code               Region  company  posted_date  \n",
       "396  23423/SN            Minnesota  Harnham          NaN  \n",
       "457  67268/TS  Nordrhein-Westfalen  Harnham          NaN  \n",
       "634       EMC           California  Harnham          NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for salary anomalies and manually correct\n",
    "info[info['salary_high']/info['salary_low']>3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lundr\\AppData\\Local\\Continuum\\anaconda3\\envs\\dsj3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\lundr\\AppData\\Local\\Continuum\\anaconda3\\envs\\dsj3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\lundr\\AppData\\Local\\Continuum\\anaconda3\\envs\\dsj3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\lundr\\AppData\\Local\\Continuum\\anaconda3\\envs\\dsj3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "C:\\Users\\lundr\\AppData\\Local\\Continuum\\anaconda3\\envs\\dsj3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\lundr\\AppData\\Local\\Continuum\\anaconda3\\envs\\dsj3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#correct the mistake\n",
    "#info.loc[info['salary_high']==max(info['salary_high']),'salary_high']=65000\n",
    "info['salary_low'][396]  = 220000\n",
    "info['salary_high'][396]  = 220000\n",
    "\n",
    "info['salary_low'][457]  = 90000\n",
    "info['salary_high'][457]  = 100000\n",
    "\n",
    "info['salary_low'][634]  = 231657\n",
    "info['salary_high'][634]  = 25604\n",
    "\n",
    "\n",
    "info['salary_average'] = (info['salary_low']+info['salary_high'])/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBP = 1.14\n",
    "USD  = 0.9\n",
    "\n",
    "# currency conversion\n",
    "info['salary_low_euros'] = info['salary_low']\n",
    "info['salary_high_euros'] = info['salary_high'] \n",
    "info['salary_average_euros'] = info['salary_average'] \n",
    "#\n",
    "\n",
    "currency = {'UK':1.14, 'Germany':1, 'USA':0.90}\n",
    "info['salary_low_euros'] = [currency[info['country'][x]]*info['salary_low'][x] for x in range(len(info['salary_low']))]\n",
    "info['salary_high_euros'] = [currency[info['country'][x]]*info['salary_high'][x] for x in range(len(info['salary_high']))]\n",
    "info['salary_average'] = [currency[info['country'][x]]*info['salary_average'][x] for x in range(len(info['salary_average']))]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 21.,  25., 139., 118., 113., 147.,  40.,  23.,  12.,   5.]),\n",
       " array([3.0000e+02, 3.2020e+04, 6.3740e+04, 9.5460e+04, 1.2718e+05,\n",
       "        1.5890e+05, 1.9062e+05, 2.2234e+05, 2.5406e+05, 2.8578e+05,\n",
       "        3.1750e+05]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAQ/ElEQVR4nO3df6xkZX3H8fenrOLv7uJezLoLXTQbKzVW6Q3F2lgjivwwQhNMIE3ZKMmmFVutNbqUpNo/TLA/tDVt1VWo2FiEogZStUoQY5qUpYvy0xVZkcLKyl6ioK1JFfvtH/NsM1zm7t07M3fv3sf3K5nMOc95Zp7v7Jn72XOfOWduqgpJUl9+YaULkCRNn+EuSR0y3CWpQ4a7JHXIcJekDq1Z6QIA1q9fX5s3b17pMiRpVbnlllserqqZUduOiHDfvHkzu3btWukyJGlVSfKfC21zWkaSOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjp0RFyhKh3JNm//3IqMe9+lZ63IuOqDR+6S1CHDXZI6ZLhLUocMd0nqkOEuSR1aNNyTXJ5kf5I7R2x7R5JKsr6tJ8kHk+xJcnuSk5ajaEnSwR3KkfvHgdPnNyY5DngNcP9Q8xnAlnbbBnxo8hIlSUu1aLhX1VeB74/Y9AHgnUANtZ0NfKIGbgLWJtkwlUolSYdsrDn3JK8HvltVt83btBF4YGh9b2uTJB1GS75CNcnTgEuA00ZtHtFWI9pIso3B1A3HH3/8UsuQJB3EOF8/8HzgBOC2JACbgK8lOZnBkfpxQ303AQ+OepKq2gHsAJidnR35H4BGW6nL4cFL4qXVYsnTMlV1R1UdW1Wbq2ozg0A/qaq+B1wHXNDOmjkFeLSq9k23ZEnSYg7lVMgrgX8HXpBkb5ILD9L988C9wB7go8Cbp1KlJGlJFp2WqarzF9m+eWi5gIsmL0uSNAmvUJWkDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocWDfcklyfZn+TOoba/SPLNJLcn+WyStUPbLk6yJ8ndSV67XIVLkhZ2KEfuHwdOn9d2PfCiqnox8C3gYoAkJwLnAb/SHvP3SY6aWrWSpEOyaLhX1VeB789r+1JVPdZWbwI2teWzgU9V1f9U1XeAPcDJU6xXknQIpjHn/ibgC215I/DA0La9re0JkmxLsivJrrm5uSmUIUk6YKJwT3IJ8BjwyQNNI7rVqMdW1Y6qmq2q2ZmZmUnKkCTNs2bcBybZCrwOOLWqDgT4XuC4oW6bgAfHL0+SNI6xwj3J6cC7gN+qqh8PbboO+Kck7weeC2wBbp64Sh0xNm//3IqMe9+lZ63IuNJqtWi4J7kSeCWwPsle4N0Mzo45Grg+CcBNVfV7VXVXkquBbzCYrrmoqn62XMVLkkZbNNyr6vwRzZcdpP97gfdOUpQkaTJeoSpJHTLcJalDhrskdchwl6QOjX2eu3Q4rdQpmNJq5ZG7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SerQouGe5PIk+5PcOdR2TJLrk9zT7te19iT5YJI9SW5PctJyFi9JGu1Qjtw/Dpw+r207cENVbQFuaOsAZwBb2m0b8KHplClJWopFw72qvgp8f17z2cAVbfkK4Jyh9k/UwE3A2iQbplWsJOnQjDvn/pyq2gfQ7o9t7RuBB4b67W1tT5BkW5JdSXbNzc2NWYYkaZRpf6CaEW01qmNV7aiq2aqanZmZmXIZkvTzbdxwf+jAdEu739/a9wLHDfXbBDw4fnmSpHGMG+7XAVvb8lbg2qH2C9pZM6cAjx6YvpEkHT5rFuuQ5ErglcD6JHuBdwOXAlcnuRC4H3hD6/554ExgD/Bj4I3LULMkaRGLhntVnb/AplNH9C3gokmLkiRNxitUJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA5NFO5J/ijJXUnuTHJlkqckOSHJziT3JLkqyZOnVawk6dCMHe5JNgJ/CMxW1YuAo4DzgPcBH6iqLcAPgAunUagk6dBNOi2zBnhqkjXA04B9wKuAa9r2K4BzJhxDkrREY4d7VX0X+Evgfgah/ihwC/BIVT3Wuu0FNo56fJJtSXYl2TU3NzduGZKkESaZllkHnA2cADwXeDpwxoiuNerxVbWjqmaranZmZmbcMiRJI0wyLfNq4DtVNVdVPwU+A/wGsLZN0wBsAh6csEZJ0hJNEu73A6ckeVqSAKcC3wBuBM5tfbYC105WoiRpqSaZc9/J4IPTrwF3tOfaAbwLeHuSPcCzgcumUKckaQnWLN5lYVX1buDd85rvBU6e5HklSZPxClVJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQxOFe5K1Sa5J8s0ku5O8LMkxSa5Pck+7XzetYiVJh2bSI/e/Af61qn4Z+FVgN7AduKGqtgA3tHVJ0mE0drgneRbwCuAygKr6SVU9ApwNXNG6XQGcM2mRkqSlmeTI/XnAHPAPSb6e5GNJng48p6r2AbT7Y0c9OMm2JLuS7Jqbm5ugDEnSfJOE+xrgJOBDVfVS4L9ZwhRMVe2oqtmqmp2ZmZmgDEnSfJOE+15gb1XtbOvXMAj7h5JsAGj3+ycrUZK0VGOHe1V9D3ggyQta06nAN4DrgK2tbStw7UQVSpKWbM2Ej/8D4JNJngzcC7yRwX8YVye5ELgfeMOEY0iSlmiicK+qW4HZEZtOneR5JUmT8QpVSeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUMTh3uSo5J8Pcm/tPUTkuxMck+Sq9ofz5YkHUbTOHJ/K7B7aP19wAeqagvwA+DCKYwhSVqCicI9ySbgLOBjbT3Aq4BrWpcrgHMmGUOStHRrJnz8XwPvBJ7Z1p8NPFJVj7X1vcDGUQ9Msg3YBnD88cdPWIbUn83bP7ci49536VkrMq6ma+wj9ySvA/ZX1S3DzSO61qjHV9WOqpqtqtmZmZlxy5AkjTDJkfvLgdcnORN4CvAsBkfya5OsaUfvm4AHJy9TkrQUYx+5V9XFVbWpqjYD5wFfrqrfAW4Ezm3dtgLXTlylJGlJluM893cBb0+yh8Ec/GXLMIYk6SAm/UAVgKr6CvCVtnwvcPI0nleSNB6vUJWkDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdWgqf6zj59VK/XV6SVqMR+6S1CGP3CU9zkr+RnrfpWet2Ni9GfvIPclxSW5MsjvJXUne2tqPSXJ9knva/brplStJOhSTTMs8BvxxVb0QOAW4KMmJwHbghqraAtzQ1iVJh9HY0zJVtQ/Y15Z/lGQ3sBE4G3hl63YF8BXgXRNVeRB+qClJTzSVD1STbAZeCuwEntOC/8B/AMdOYwxJ0qGbONyTPAP4NPC2qvrhEh63LcmuJLvm5uYmLUOSNGSicE/yJAbB/smq+kxrfijJhrZ9A7B/1GOrakdVzVbV7MzMzCRlSJLmmeRsmQCXAbur6v1Dm64DtrblrcC145cnSRrHJOe5vxz4XeCOJLe2tj8BLgWuTnIhcD/whslKlCQt1SRny/wbkAU2nzru80qSJufXD0hShwx3SeqQ4S5JHTLcJalDhrskdchwl6QO+X3uko4YK/VFgD1+j7xH7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CGvUJX0c2+lroyF5bs61iN3SeqQ4S5JHTLcJalDyxbuSU5PcneSPUm2L9c4kqQnWpZwT3IU8HfAGcCJwPlJTlyOsSRJT7RcR+4nA3uq6t6q+gnwKeDsZRpLkjTPcp0KuRF4YGh9L/Drwx2SbAO2tdX/SnL3mGOtBx4e87FHAutfWda/sn7u68/7Jhr/lxbasFzhnhFt9biVqh3AjokHSnZV1eykz7NSrH9lWf/Ksv7ls1zTMnuB44bWNwEPLtNYkqR5livc/wPYkuSEJE8GzgOuW6axJEnzLMu0TFU9luQtwBeBo4DLq+qu5RiLKUztrDDrX1nWv7Ksf5mkqhbvJUlaVbxCVZI6ZLhLUodWdbgfSV9xkOS+JHckuTXJrtZ2TJLrk9zT7te19iT5YKv79iQnDT3P1tb/niRbh9p/rT3/nvbYUaebLqXey5PsT3LnUNuy17vQGFOq/z1Jvtv2wa1JzhzadnGr5e4krx1qH/keaicD7Gx1XtVODCDJ0W19T9u+ecz6j0tyY5LdSe5K8tbWvir2wUHqXxX7IMlTktyc5LZW/5+NO+a0XtfUVdWqvDH4oPbbwPOAJwO3ASeuYD33Aevntf05sL0tbwfe15bPBL7A4HqAU4Cdrf0Y4N52v64tr2vbbgZe1h7zBeCMCet9BXAScOfhrHehMaZU/3uAd4zoe2J7fxwNnNDeN0cd7D0EXA2c15Y/DPx+W34z8OG2fB5w1Zj1bwBOasvPBL7V6lwV++Ag9a+KfdD+TZ7Rlp8E7Gz/rksac5qva9q3FQnCqRQ+eNN+cWj9YuDiFaznPp4Y7ncDG9ryBuDutvwR4Pz5/YDzgY8MtX+ktW0AvjnU/rh+E9S8mceH47LXu9AYU6r/PYwOlse9NxicxfWyhd5D7Qf/YWDN/Pfagce25TWtX6awL64FXrPa9sGI+lfdPgCeBnyNwVX0Sxpzmq9r2rfVPC0z6isONq5QLTC4AvdLSW7J4KsVAJ5TVfsA2v2xrX2h2g/WvndE+7QdjnoXGmNa3tKmLS4fmm5Yav3PBh6pqsdG1P//j2nbH239x9Z+xX8pg6PHVbcP5tUPq2QfJDkqya3AfuB6BkfaSx1zmq9rqlZzuC/6FQeH2cur6iQG34R5UZJXHKTvQrUvtf1wWS31fgh4PvASYB/wV619mvVP9bUleQbwaeBtVfXDg3VdYNwV3Qcj6l81+6CqflZVL2FwBf3JwAvHGPOI3C+wusP9iPqKg6p6sN3vBz7L4M3yUJINAO1+f+u+UO0Ha980on3aDke9C40xsap6qP3A/i/wUQb7YJz6HwbWJlkzr/1xz9W2/yLw/XHqTfIkBsH4yar6TGteNftgVP2rbR+0mh8BvsJgzn2pY07zdU3Vag73I+YrDpI8PckzDywDpwF3tnoOnL2wlcG8JK39gnYGxCnAo+3X4y8CpyVZ136dPY3BfNw+4EdJTmlnPFww9FzTdDjqXWiMiR0IrOa3GeyDA2Oe1854OAHYwuDDxpHvoRpMht4InLvAv8WB+s8Fvtz6L7XWAJcBu6vq/UObVsU+WKj+1bIPkswkWduWnwq8Gtg9xpjTfF3TtRwT+YfrxuAMgm8xmCu7ZAXreB6DT8NvA+46UAuD+bUbgHva/TGtPQz+mMm3gTuA2aHnehOwp93eONQ+y+AH5dvA3zLhh3jAlQx+bf4pg6OMCw9HvQuNMaX6/7HVdzuDH7oNQ/0vabXczdCZRgu9h9o+vbm9rn8Gjm7tT2nre9r2541Z/28y+HX8duDWdjtzteyDg9S/KvYB8GLg663OO4E/HXfMab2uad/8+gFJ6tBqnpaRJC3AcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkd+j8B8DxyAjxC5wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.hist(info['salary_average'][info['jobtype']!='Contract'])\n",
    "plt.hist(info['salary_average_euros'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = info[info['salary_type']=='yearly'].groupby(by='Region').agg({'salary_average_euros' : ['count','mean','median','min','max']}).sort_values(by = ('salary_average_euros', 'mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">salary_average_euros</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baden-Württemberg</th>\n",
       "      <td>6</td>\n",
       "      <td>66916</td>\n",
       "      <td>63750</td>\n",
       "      <td>56500</td>\n",
       "      <td>80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hessen</th>\n",
       "      <td>3</td>\n",
       "      <td>73333</td>\n",
       "      <td>75000</td>\n",
       "      <td>65000</td>\n",
       "      <td>80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Berlin</th>\n",
       "      <td>44</td>\n",
       "      <td>73382</td>\n",
       "      <td>70000</td>\n",
       "      <td>42500</td>\n",
       "      <td>105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nordrhein-Westfalen</th>\n",
       "      <td>21</td>\n",
       "      <td>74642</td>\n",
       "      <td>75000</td>\n",
       "      <td>45000</td>\n",
       "      <td>110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sachsen</th>\n",
       "      <td>1</td>\n",
       "      <td>75000</td>\n",
       "      <td>75000</td>\n",
       "      <td>75000</td>\n",
       "      <td>75000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hamburg</th>\n",
       "      <td>20</td>\n",
       "      <td>75750</td>\n",
       "      <td>73750</td>\n",
       "      <td>45000</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bayern</th>\n",
       "      <td>36</td>\n",
       "      <td>77708</td>\n",
       "      <td>76250</td>\n",
       "      <td>45000</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virginia</th>\n",
       "      <td>4</td>\n",
       "      <td>94375</td>\n",
       "      <td>95000</td>\n",
       "      <td>82500</td>\n",
       "      <td>105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maryland</th>\n",
       "      <td>3</td>\n",
       "      <td>105000</td>\n",
       "      <td>105000</td>\n",
       "      <td>100000</td>\n",
       "      <td>110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Florida</th>\n",
       "      <td>2</td>\n",
       "      <td>108750</td>\n",
       "      <td>108750</td>\n",
       "      <td>97500</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wisconsin</th>\n",
       "      <td>1</td>\n",
       "      <td>110000</td>\n",
       "      <td>110000</td>\n",
       "      <td>110000</td>\n",
       "      <td>110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>17</td>\n",
       "      <td>122169</td>\n",
       "      <td>106684</td>\n",
       "      <td>70000</td>\n",
       "      <td>213368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Washington</th>\n",
       "      <td>7</td>\n",
       "      <td>141010</td>\n",
       "      <td>135000</td>\n",
       "      <td>112500</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>165</td>\n",
       "      <td>145281</td>\n",
       "      <td>134117</td>\n",
       "      <td>52500</td>\n",
       "      <td>317500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Massachusetts</th>\n",
       "      <td>101</td>\n",
       "      <td>146100</td>\n",
       "      <td>150000</td>\n",
       "      <td>70000</td>\n",
       "      <td>213368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North Carolina</th>\n",
       "      <td>3</td>\n",
       "      <td>146666</td>\n",
       "      <td>120000</td>\n",
       "      <td>110000</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Jersey</th>\n",
       "      <td>2</td>\n",
       "      <td>151250</td>\n",
       "      <td>151250</td>\n",
       "      <td>150000</td>\n",
       "      <td>152500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tennessee</th>\n",
       "      <td>2</td>\n",
       "      <td>160000</td>\n",
       "      <td>160000</td>\n",
       "      <td>160000</td>\n",
       "      <td>160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oregon</th>\n",
       "      <td>9</td>\n",
       "      <td>169955</td>\n",
       "      <td>175000</td>\n",
       "      <td>75000</td>\n",
       "      <td>255000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>150</td>\n",
       "      <td>170897</td>\n",
       "      <td>173750</td>\n",
       "      <td>60000</td>\n",
       "      <td>304812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <td>3</td>\n",
       "      <td>179732</td>\n",
       "      <td>210000</td>\n",
       "      <td>73154</td>\n",
       "      <td>256042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utah</th>\n",
       "      <td>3</td>\n",
       "      <td>180000</td>\n",
       "      <td>190000</td>\n",
       "      <td>160000</td>\n",
       "      <td>190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Illinois</th>\n",
       "      <td>10</td>\n",
       "      <td>181443</td>\n",
       "      <td>172219</td>\n",
       "      <td>125000</td>\n",
       "      <td>240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ohio</th>\n",
       "      <td>1</td>\n",
       "      <td>192031</td>\n",
       "      <td>192031</td>\n",
       "      <td>192031</td>\n",
       "      <td>192031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minnesota</th>\n",
       "      <td>8</td>\n",
       "      <td>222479</td>\n",
       "      <td>215000</td>\n",
       "      <td>190000</td>\n",
       "      <td>256042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    salary_average_euros                                \n",
       "                                   count    mean  median     min     max\n",
       "Region                                                                  \n",
       "Baden-Württemberg                      6   66916   63750   56500   80000\n",
       "Hessen                                 3   73333   75000   65000   80000\n",
       "Berlin                                44   73382   70000   42500  105000\n",
       "Nordrhein-Westfalen                   21   74642   75000   45000  110000\n",
       "Sachsen                                1   75000   75000   75000   75000\n",
       "Hamburg                               20   75750   73750   45000  120000\n",
       "Bayern                                36   77708   76250   45000  120000\n",
       "Virginia                               4   94375   95000   82500  105000\n",
       "Maryland                               3  105000  105000  100000  110000\n",
       "Florida                                2  108750  108750   97500  120000\n",
       "Wisconsin                              1  110000  110000  110000  110000\n",
       "                                      17  122169  106684   70000  213368\n",
       "Washington                             7  141010  135000  112500  175000\n",
       "New York                             165  145281  134117   52500  317500\n",
       "Massachusetts                        101  146100  150000   70000  213368\n",
       "North Carolina                         3  146666  120000  110000  210000\n",
       "New Jersey                             2  151250  151250  150000  152500\n",
       "Tennessee                              2  160000  160000  160000  160000\n",
       "Oregon                                 9  169955  175000   75000  255000\n",
       "California                           150  170897  173750   60000  304812\n",
       "Texas                                  3  179732  210000   73154  256042\n",
       "Utah                                   3  180000  190000  160000  190000\n",
       "Illinois                              10  181443  172219  125000  240000\n",
       "Ohio                                   1  192031  192031  192031  192031\n",
       "Minnesota                              8  222479  215000  190000  256042"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.applymap(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(info.shape[0]):\n",
    "    for y in range(info.shape[1]):\n",
    "        if info.iloc[x,y] =='None' or info.iloc[x,y] =='Nothing_found':\n",
    "            info.iloc[x,y] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['New York', 'California', 'Massachusetts', 'North Carolina', '',\n",
       "       'Maryland', 'New Jersey', 'Washington', 'Oregon', 'Illinois',\n",
       "       'Utah', 'Tennessee', 'Wisconsin', 'Texas', 'Minnesota', 'Ohio',\n",
       "       'Nordrhein-Westfalen', 'Hamburg', 'Bayern', 'Sachsen', 'Berlin',\n",
       "       'Hessen', 'Baden-Württemberg', 'Florida', 'Virginia'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.Region.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# job_title, company, description, salary, salary_low, salary_high, salary_average,salary_low_euros, salary_high_euros, salary_average_euros,  location, jobtype,posted_date, extraction_date, country, region\n",
    "info['jobtype'] = info['type']\n",
    "info['currency'] = info['country']\n",
    "info['currency'] = info['currency'].map({\"UK\":\"£\",\"Germany\":\"€\",\"USA\":\"$\"})\n",
    "info['region'] = info['Region']\n",
    "info['language'] = info.description.apply(detect)\n",
    "data_to_database = info[['job_title','url','ref_code', 'company', 'description', 'salary', 'salary_low', 'salary_high', 'currency','salary_average','salary_low_euros', 'salary_high_euros', 'salary_average_euros', 'salary_type', 'location', 'jobtype','posted_date', 'extraction_date', 'country', 'region','language']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle out the data for good measure\n",
    "data_to_database.to_pickle(\"C:/Users/lundr/DataScienceJobs/data/harnham_all_CLEAN_15-11-19.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\lundr\\\\DSJ\\\\DataScienceJobs\\\\Cleaning'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Landing page is currently empty.\n",
      "\n",
      "Uploading data to landing page...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#connect to the database\n",
    "import os \n",
    "os.getcwd()\n",
    "#os.chdir('..')\n",
    "\n",
    "PASSWORD = pd.read_pickle('C:/Users/lundr/DataScienceJobs/data/SQL_access.pkl')\n",
    "\n",
    "import SQL.db_upload as db\n",
    "\n",
    "db.db_upload(PASSWORD, data_to_database)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['New York', 'California', 'Massachusetts', 'North Carolina', '',\n",
       "       'Maryland', 'New Jersey', 'Washington', 'Oregon', 'Illinois',\n",
       "       'Utah', 'Tennessee', 'Wisconsin', 'Texas', 'Minnesota', 'Ohio',\n",
       "       'Nordrhein-Westfalen', 'Hamburg', 'Bayern', 'Sachsen', 'Berlin',\n",
       "       'Hessen', 'Baden-Württemberg', 'Florida', 'Virginia'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info['region'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>extraction_date</th>\n",
       "      <th>job_ref</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_high</th>\n",
       "      <th>salary_low</th>\n",
       "      <th>...</th>\n",
       "      <th>company</th>\n",
       "      <th>posted_date</th>\n",
       "      <th>salary_average</th>\n",
       "      <th>salary_low_euros</th>\n",
       "      <th>salary_high_euros</th>\n",
       "      <th>salary_average_euros</th>\n",
       "      <th>jobtype</th>\n",
       "      <th>currency</th>\n",
       "      <th>region</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>' ', ' the company', \" by combining advanced ...</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>[125479082345]</td>\n",
       "      <td>Senior Data Scientist - MULTIPLE ROLES: Statis...</td>\n",
       "      <td>'New York'</td>\n",
       "      <td>US$150000 - US$175000 per year + EQ</td>\n",
       "      <td>175000.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Harnham</td>\n",
       "      <td>NaN</td>\n",
       "      <td>146250.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>162500.0</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>$</td>\n",
       "      <td>New York</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>USA</td>\n",
       "      <td>' ', 'as a principal data scientist, you will...</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>[18265RS]</td>\n",
       "      <td>THE COMPANY:</td>\n",
       "      <td>'Santa Clara, California'</td>\n",
       "      <td>US$180000 - US$200000 per annum</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Harnham</td>\n",
       "      <td>NaN</td>\n",
       "      <td>171000.0</td>\n",
       "      <td>162000.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>190000.0</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>$</td>\n",
       "      <td>California</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>USA</td>\n",
       "      <td>' ', 'harnham are partnered exclusively with ...</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>[40739 VACTJ]</td>\n",
       "      <td>THE COMPANY</td>\n",
       "      <td>'New York'</td>\n",
       "      <td>US$140000 - US$160000 per annum + Bonus + Bene...</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Harnham</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>126000.0</td>\n",
       "      <td>144000.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>$</td>\n",
       "      <td>New York</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>USA</td>\n",
       "      <td>' new york, new york$140,000-170,000 base sal...</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>[69271 VACTJ]</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>'New York'</td>\n",
       "      <td>US$140000 - US$170000 per annum + Equity + Ben...</td>\n",
       "      <td>170000.0</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Harnham</td>\n",
       "      <td>NaN</td>\n",
       "      <td>139500.0</td>\n",
       "      <td>126000.0</td>\n",
       "      <td>153000.0</td>\n",
       "      <td>155000.0</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>$</td>\n",
       "      <td>New York</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>USA</td>\n",
       "      <td>' ', 'boston, ma', 'usd $170000', ' ', 'a rev...</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>[362362]</td>\n",
       "      <td>TV Data Scientist</td>\n",
       "      <td>'Boston, Massachusetts'</td>\n",
       "      <td>US$150000 - US$170000 per year</td>\n",
       "      <td>170000.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Harnham</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144000.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>153000.0</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>$</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index country                                        description  \\\n",
       "0      0     USA   ' ', ' the company', \" by combining advanced ...   \n",
       "1      1     USA   ' ', 'as a principal data scientist, you will...   \n",
       "2      2     USA   ' ', 'harnham are partnered exclusively with ...   \n",
       "3      3     USA   ' new york, new york$140,000-170,000 base sal...   \n",
       "4      4     USA   ' ', 'boston, ma', 'usd $170000', ' ', 'a rev...   \n",
       "\n",
       "  extraction_date         job_ref  \\\n",
       "0      2019-12-03  [125479082345]   \n",
       "1      2019-12-03       [18265RS]   \n",
       "2      2019-12-03   [40739 VACTJ]   \n",
       "3      2019-12-03   [69271 VACTJ]   \n",
       "4      2019-12-03        [362362]   \n",
       "\n",
       "                                           job_title  \\\n",
       "0  Senior Data Scientist - MULTIPLE ROLES: Statis...   \n",
       "1                                       THE COMPANY:   \n",
       "2                                        THE COMPANY   \n",
       "3                          Machine Learning Engineer   \n",
       "4                                  TV Data Scientist   \n",
       "\n",
       "                      location  \\\n",
       "0                  'New York'    \n",
       "1   'Santa Clara, California'    \n",
       "2                  'New York'    \n",
       "3                  'New York'    \n",
       "4     'Boston, Massachusetts'    \n",
       "\n",
       "                                              salary  salary_high  salary_low  \\\n",
       "0                US$150000 - US$175000 per year + EQ     175000.0    150000.0   \n",
       "1                    US$180000 - US$200000 per annum     200000.0    180000.0   \n",
       "2  US$140000 - US$160000 per annum + Bonus + Bene...     160000.0    140000.0   \n",
       "3  US$140000 - US$170000 per annum + Equity + Ben...     170000.0    140000.0   \n",
       "4                     US$150000 - US$170000 per year     170000.0    150000.0   \n",
       "\n",
       "   ...  company posted_date salary_average salary_low_euros salary_high_euros  \\\n",
       "0  ...  Harnham         NaN       146250.0         135000.0          157500.0   \n",
       "1  ...  Harnham         NaN       171000.0         162000.0          180000.0   \n",
       "2  ...  Harnham         NaN       135000.0         126000.0          144000.0   \n",
       "3  ...  Harnham         NaN       139500.0         126000.0          153000.0   \n",
       "4  ...  Harnham         NaN       144000.0         135000.0          153000.0   \n",
       "\n",
       "  salary_average_euros    jobtype  currency         region  language  \n",
       "0             162500.0  Permanent         $       New York        en  \n",
       "1             190000.0  Permanent         $     California        en  \n",
       "2             150000.0  Permanent         $       New York        en  \n",
       "3             155000.0  Permanent         $       New York        en  \n",
       "4             160000.0  Permanent         $  Massachusetts        en  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
